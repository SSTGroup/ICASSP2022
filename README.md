# Simulations for ICASSP2022 Paper

This package contains the code for reproducing the simulations of our paper:

Isabell Lehmann, Evrim Acar, et. al, **Multi-task fMRI Data Fusion Using IVA and PARAFAC2**, *2022
IEEE International Conference on Acoustics, Speech and Signal Processing*, 2022.

## Installing this Package

The only pre-requisite is to have **Python 3** (version >=3.6) installed. This package can be
installed (optionally in a virtual environment) with:

    git clone https://github.com/SSTGroup/ICASSP2022
    cd ICASSP2022
    pip install -e .

Required third party packages will automatically be installed.

## Generating Simulations and Results

We recommend to run the code on a server or external PC because it has a long computation time
(3 days for us).
The simulated data is generated with:

    cd ICASSP
    python simulations.py @../simulations/simulation_parameters.txt

After running the code, the folder *ICASSP2022/simulations* will contain the generated .npy files,
consisting of the true data and the estimations by IVA and PARAFAC2, for each Monte-Carlo run.

Then, the performance metrics are calcuted with (from the ICASSP folder):

    python performance_metrics.py @../simulations/performance_parameters.txt

The .npy files containing the performace metrics will also be saved in the *simulations* folder.

## Visualizing Results

After having calculated the performance metrics, the boxplots can be generated by running the
notebook.
The *metrics_scenario_1/2.npy* files must be in the *simulations* folder. 

## Changing Parameters

By changing the scenario in *parameters.txt*, the simulations for scenario 1 or 2 are generated.
The other parameters are set to the values according to the simulations in our paper.
The default values can be changed by adding the parameters to the *simulation_parameters.txt* or
*performance_parameters.txt* files.

## Contact

In case of questions, suggestions, problems etc. please send an email to isabell.lehmann@sst.upb.de,
or open an issue here on Github.

## Citing

If you use this code in an academic paper, please cite [1]

    @inproceedings{Lehmann2022,
      author  = {Lehmann, Isabell and Acar, Evrim and Hasija, Tanuj and Akhonda, M.A.B.S. and Calhoun, Vince D. and Schreier, Peter J. and Adali, Tulay},
      title   = {Multi-task fMRI Data Fusion Using IVA and PARAFAC2},
      journal = {2022 IEEE International Conference on Acoustics, Speech and Signal Processing},
	  year = {2022}
    }

[1] Isabell Lehmann, Evrim Acar, et. al, **Multi-task fMRI Data Fusion Using IVA and PARAFAC2**, *
2022 IEEE International Conference on Acoustics, Speech and Signal Processing*, 2022.



